{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Digit_Classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rrx9QJ6jbJXT",
        "colab_type": "text"
      },
      "source": [
        "***Importing the dependencies***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXL9efhDbA9G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrdUIyuic17f",
        "colab_type": "text"
      },
      "source": [
        "***Importing the MNIST dataset for digit classification***\n",
        "\n",
        "*The MNIST database is a large database consisting of images of numbers often used for classification training*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5utHJ0dQTAR1",
        "colab_type": "code",
        "outputId": "a6c38f39-2df5-45dc-f615-c7e3145d6079",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist_data = input_data.read_data_sets(\"./data\", one_hot = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0804 14:44:21.906900 140093001369472 deprecation.py:323] From <ipython-input-2-4cf8105ac99b>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "W0804 14:44:21.908698 140093001369472 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "W0804 14:44:21.916080 140093001369472 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "W0804 14:44:22.203264 140093001369472 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Extracting ./data/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0804 14:44:22.579874 140093001369472 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "W0804 14:44:22.587257 140093001369472 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Extracting ./data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting ./data/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0804 14:44:22.866836 140093001369472 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting ./data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr2fjjq5TSeL",
        "colab_type": "code",
        "outputId": "4763e406-a75a-4fc1-ecee-8a5d391c2dd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "num_training = mnist_data.train.num_examples #55,000\n",
        "num_testing = mnist_data.test.num_examples #10,000\n",
        "num_validation = mnist_data.validation.num_examples #5,000\n",
        "print(\"MNIST Datasize: Training samples: {0}, Testing samples: {1}, Vaidation sampled: {2}\".format(num_training, num_testing, num_validation))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MNIST Datasize: Training samples: 55000, Testing samples: 10000, Vaidation sampled: 5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-NRFlcKcsss",
        "colab_type": "text"
      },
      "source": [
        "***Neural Network parameters***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xcdo3e15aerX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#architecture of neural network\n",
        "n_input = 784 #input image of size 28 x 28 pixels\n",
        "n_hidden_1 = 512 #no of nodes in First hidden layer\n",
        "n_hidden_2 = 256 #no of nodes in Second hidden layer\n",
        "n_hidden_3 = 128 #no of nodes in Third hidden layer\n",
        "n_hidden_4 = 64\n",
        "n_output =10 #Output layer having (0-9) digits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuGIvNBF6tQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#hyperparameters - don't change throughout the program\n",
        "learning_rate = 1e-4 #larger number makes the process faster but values may ted to overshoot the optimal value\n",
        "epochs = 3000\n",
        "batch_size = 128\n",
        "keep_prob = tf.placeholder(tf.float32) #used to implement the dropout feature of hidden layers to avoid overfitting"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUIM4YsldhGa",
        "colab_type": "text"
      },
      "source": [
        "***Building the tensorflow graph***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMqmg_6VdlQ0",
        "colab_type": "code",
        "outputId": "60e124b4-1d7e-4a9a-ed57-86a6c39c7787",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "#placeholders\n",
        "X = tf.placeholder(tf.float32, [None, n_input]) #n_input = 784\n",
        "Y = tf.placeholder(tf.float32, [None, n_output]) #n_output = 10\n",
        "\n",
        "#weight defination\n",
        "nn_weight = {\"W1\" : tf.Variable(tf.random_normal([n_input, n_hidden_1], stddev = 0.1)),\n",
        "            \"W2\" : tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2], stddev = 0.1)),\n",
        "            \"W3\" : tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3], stddev = 0.1)),\n",
        "            \"W4\" : tf.Variable(tf.random_normal([n_hidden_3, n_hidden_4], stddev=0.1)),\n",
        "            \"Wout\" : tf.Variable(tf.random_normal([n_hidden_4, n_output], stddev = 0.1))\n",
        "            }\n",
        "\n",
        "nn_bias = { \"B1\": tf.Variable(tf.random_normal([n_hidden_1])),\n",
        "           \"B2\": tf.Variable(tf.random_normal([n_hidden_2])),\n",
        "           \"B3\": tf.Variable(tf.random_normal([n_hidden_3])),\n",
        "           \"B4\": tf.Variable(tf.random_normal([n_hidden_4])),\n",
        "           \"B5\": tf.Variable(tf.random_normal([n_output]))\n",
        "          }\n",
        "\n",
        "#Creating the NN model\n",
        "\n",
        "with tf.name_scope(\"Network_Model\") as scope:\n",
        "  #layer = (previous_layer * current_weight) + bias (all operations are matrix operations)\n",
        "  nn_layer_1 = tf.add(tf.matmul(X, nn_weight[\"W1\"]), nn_bias[\"B1\"])\n",
        "  nn_layer_2 = tf.add(tf.matmul(nn_layer_1, nn_weight[\"W2\"]), nn_bias[\"B2\"])\n",
        "  nn_layer_3 = tf.add(tf.matmul(nn_layer_2, nn_weight[\"W3\"]), nn_bias[\"B3\"])\n",
        "  nn_layer_4 = tf.add(tf.matmul(nn_layer_3, nn_weight[\"W4\"]), nn_bias[\"B4\"])\n",
        "  layer_drop = tf.nn.dropout(nn_layer_4, keep_prob)\n",
        "  output_layer = tf.nn.sigmoid(output_layer)\n",
        "  \n",
        "#Summary report for weights of neural networks\n",
        "W1_histogram = tf.summary.histogram(\"W1\", nn_weight[\"W1\"])\n",
        "W2_histogram = tf.summary.histogram(\"W2\", nn_weight[\"W2\"])\n",
        "W3_histogram = tf.summary.histogram(\"W3\", nn_weight[\"W3\"])\n",
        "W4_histogram = tf.summary.histogram(\"W4\", nn_weight[\"W4\"])\n",
        "Wout_histogram = tf.summary.histogram(\"Wout\", nn_weight[\"Wout\"])\n",
        "\n",
        "#Summary report for weights of neural networks\n",
        "B1_histogram = tf.summary.histogram(\"B1\", nn_bias[\"B1\"])\n",
        "B2_histogram = tf.summary.histogram(\"B2\", nn_bias[\"B2\"])\n",
        "B3_histogram = tf.summary.histogram(\"B3\", nn_bias[\"B3\"])\n",
        "B4_histogram = tf.summary.histogram(\"B4\", nn_bias[\"B4\"])\n",
        "B5_histogram = tf.summary.histogram(\"B5\", nn_bias[\"B5\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0804 14:44:38.176834 140093001369472 deprecation.py:506] From <ipython-input-6-752d6787510e>:31: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKJTmptq6rdY",
        "colab_type": "code",
        "outputId": "5b307377-bbcd-4965-dda7-73a509466191",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Define loss\n",
        "with tf.name_scope(\"Cost_function\") as scope:\n",
        "  computed_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = output_layer, labels = Y))\n",
        "\n",
        "#Summary for the cost\n",
        "network_cost = tf.summary.scalar(\"Cost\", computed_loss)\n",
        "\n",
        "#Define the optimiser\n",
        "with tf.name_scope(\"Network_Optimizer\") as scope:\n",
        "  optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(computed_loss)\n",
        "\n",
        "#Define prediction\n",
        "with tf.name_scope(\"Network_Prediction\") as scope:\n",
        "  prediction_out = tf.equal(tf.argmax(output_layer, 1), tf.argmax(Y,1))\n",
        "\n",
        "#Define accuracy of the model\n",
        "with tf.name_scope(\"Network_Accuracy\") as scope:\n",
        "  nn_accuracy = tf.reduce_mean(tf.cast(prediction_out, tf.float32))\n",
        "\n",
        "#Initialize all the variables\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "#Merging all of the summaries\n",
        "merged_summary = tf.summary.merge_all()\n",
        "\n",
        "#Saving the model\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "print(\"Model saved\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqRvwKO6msLx",
        "colab_type": "text"
      },
      "source": [
        "***Executing the computational graph***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnXLp6Q5mvjG",
        "colab_type": "code",
        "outputId": "01dfdc17-27ba-4137-ebec-bae9b7ee85d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  writer = tf.summary.FileWriter(\"./log\", sess.graph)\n",
        "  for i in range(epochs):\n",
        "    \n",
        "    #dataset in mini batches\n",
        "    mini_batch_x, mini_batch_y = mnist_data.train.next_batch(batch_size)\n",
        "    #print (mini_batch_x[0:1,:].shape)\n",
        "    \n",
        "    #validation datasets in mini batches\n",
        "    mini_batch_val_x, mini_batch_val_y = mnist_data.validation.next_batch(batch_size)\n",
        "    \n",
        "    #Running the optimizer\n",
        "    sess.run(optimizer, feed_dict = {X: mini_batch_x, Y: mini_batch_y, keep_prob: 1.0})\n",
        "    \n",
        "    #Running the summary\n",
        "    summary_epoch = sess.run(merged_summary, feed_dict = {X:mini_batch_x, Y: mini_batch_y, keep_prob: 1.0})\n",
        "    writer.add_summary(summary_epoch, i)\n",
        "    \n",
        "    #after every 100th epoch\n",
        "    if i%100 == 0:\n",
        "      #testing loss and accuracy\n",
        "      mini_batch_loss, mini_batch_accuracy =  sess.run([computed_loss, nn_accuracy], feed_dict = {X: mini_batch_x, Y: mini_batch_y, keep_prob: 1.0})\n",
        "      \n",
        "      #validation loss and accuracy\n",
        "      mini_batch_val_loss, mini_batch_val_accuracy =  sess.run([computed_loss, nn_accuracy], feed_dict = {X: mini_batch_val_x, Y: mini_batch_val_y, keep_prob: 1.0})\n",
        "      print(\"Iterations : {0}, Train_loss: {1}, Train_accuracy: {2}, Val_loss: {3}, Val_accuracy: {4}\".format(i, mini_batch_loss, mini_batch_accuracy, mini_batch_val_loss, mini_batch_val_accuracy))\n",
        "      \n",
        "  print(\"Optimization finished\")\n",
        "  test_accuracy = sess.run(nn_accuracy, feed_dict = {X: mnist_data.test.images, Y: mnist_data.test.labels, keep_prob: 1.0})\n",
        "  print(\"Testing accuracy is {0}\".format(test_accuracy))\n",
        "\n",
        "  saver_path = saver.save(sess, \"./model/my_model.ckpt\")\n",
        "  \n",
        "  #accuracy can be improved by changing the value of keep_prob only in the train, but in the tetsing phase it is advised to keep the value as 1 because we dont want to drop any features"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iterations : 0, Train_loss: 2.3122127056121826, Train_accuracy: 0.09375, Val_loss: 2.328822374343872, Val_accuracy: 0.046875\n",
            "Iterations : 100, Train_loss: 2.31663179397583, Train_accuracy: 0.09375, Val_loss: 2.3122425079345703, Val_accuracy: 0.09375\n",
            "Iterations : 200, Train_loss: 2.2989509105682373, Train_accuracy: 0.1171875, Val_loss: 2.3056533336639404, Val_accuracy: 0.109375\n",
            "Iterations : 300, Train_loss: 2.301064968109131, Train_accuracy: 0.109375, Val_loss: 2.3304667472839355, Val_accuracy: 0.09375\n",
            "Iterations : 400, Train_loss: 2.302570343017578, Train_accuracy: 0.1015625, Val_loss: 2.3052849769592285, Val_accuracy: 0.109375\n",
            "Iterations : 500, Train_loss: 2.3201816082000732, Train_accuracy: 0.0546875, Val_loss: 2.3144843578338623, Val_accuracy: 0.09375\n",
            "Iterations : 600, Train_loss: 2.3077807426452637, Train_accuracy: 0.078125, Val_loss: 2.3025999069213867, Val_accuracy: 0.109375\n",
            "Iterations : 700, Train_loss: 2.3098304271698, Train_accuracy: 0.0859375, Val_loss: 2.3178930282592773, Val_accuracy: 0.0859375\n",
            "Iterations : 800, Train_loss: 2.310709238052368, Train_accuracy: 0.09375, Val_loss: 2.3157942295074463, Val_accuracy: 0.0859375\n",
            "Iterations : 900, Train_loss: 2.2954206466674805, Train_accuracy: 0.15625, Val_loss: 2.305457592010498, Val_accuracy: 0.1171875\n",
            "Iterations : 1000, Train_loss: 2.323122501373291, Train_accuracy: 0.09375, Val_loss: 2.305570125579834, Val_accuracy: 0.1015625\n",
            "Iterations : 1100, Train_loss: 2.3124003410339355, Train_accuracy: 0.125, Val_loss: 2.319427013397217, Val_accuracy: 0.0625\n",
            "Iterations : 1200, Train_loss: 2.30322265625, Train_accuracy: 0.109375, Val_loss: 2.2930216789245605, Val_accuracy: 0.1484375\n",
            "Iterations : 1300, Train_loss: 2.324042320251465, Train_accuracy: 0.078125, Val_loss: 2.2929534912109375, Val_accuracy: 0.1640625\n",
            "Iterations : 1400, Train_loss: 2.3289361000061035, Train_accuracy: 0.0625, Val_loss: 2.30776309967041, Val_accuracy: 0.1328125\n",
            "Iterations : 1500, Train_loss: 2.317518472671509, Train_accuracy: 0.078125, Val_loss: 2.321169137954712, Val_accuracy: 0.078125\n",
            "Iterations : 1600, Train_loss: 2.3167529106140137, Train_accuracy: 0.0703125, Val_loss: 2.293147563934326, Val_accuracy: 0.140625\n",
            "Iterations : 1700, Train_loss: 2.3058323860168457, Train_accuracy: 0.1171875, Val_loss: 2.317925453186035, Val_accuracy: 0.0625\n",
            "Iterations : 1800, Train_loss: 2.3124098777770996, Train_accuracy: 0.078125, Val_loss: 2.312548875808716, Val_accuracy: 0.0546875\n",
            "Iterations : 1900, Train_loss: 2.306581497192383, Train_accuracy: 0.09375, Val_loss: 2.3152859210968018, Val_accuracy: 0.0703125\n",
            "Iterations : 2000, Train_loss: 2.3189985752105713, Train_accuracy: 0.109375, Val_loss: 2.3085269927978516, Val_accuracy: 0.1015625\n",
            "Iterations : 2100, Train_loss: 2.306328296661377, Train_accuracy: 0.1171875, Val_loss: 2.305294990539551, Val_accuracy: 0.109375\n",
            "Iterations : 2200, Train_loss: 2.306994915008545, Train_accuracy: 0.0625, Val_loss: 2.3087570667266846, Val_accuracy: 0.0703125\n",
            "Iterations : 2300, Train_loss: 2.2987208366394043, Train_accuracy: 0.15625, Val_loss: 2.3108325004577637, Val_accuracy: 0.0859375\n",
            "Iterations : 2400, Train_loss: 2.3106088638305664, Train_accuracy: 0.1171875, Val_loss: 2.3016560077667236, Val_accuracy: 0.1015625\n",
            "Iterations : 2500, Train_loss: 2.3141186237335205, Train_accuracy: 0.0703125, Val_loss: 2.325101375579834, Val_accuracy: 0.0859375\n",
            "Iterations : 2600, Train_loss: 2.3097920417785645, Train_accuracy: 0.0859375, Val_loss: 2.2994322776794434, Val_accuracy: 0.125\n",
            "Iterations : 2700, Train_loss: 2.313652515411377, Train_accuracy: 0.0859375, Val_loss: 2.3187146186828613, Val_accuracy: 0.0703125\n",
            "Iterations : 2800, Train_loss: 2.31109881401062, Train_accuracy: 0.109375, Val_loss: 2.2962939739227295, Val_accuracy: 0.125\n",
            "Iterations : 2900, Train_loss: 2.3177714347839355, Train_accuracy: 0.0625, Val_loss: 2.310914993286133, Val_accuracy: 0.0625\n",
            "Optimization finished\n",
            "Testing accuracy is 0.09740000218153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGTbfAeM1sG2",
        "colab_type": "text"
      },
      "source": [
        "***Testing the model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMKfj69D1uO7",
        "colab_type": "code",
        "outputId": "ce258d58-f71e-4e9a-f75e-15847917a32b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "#Upload the test image from outside\n",
        "\n",
        "img = cv2.imread(\"7.jpg\")\n",
        "gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "rescaled_image = cv2.resize(gray_image, (28,28))\n",
        "plt.imshow(rescaled_image, cmap = 'gray')\n",
        "plt.show()\n",
        "rescaled_image.shape\n",
        "#test_image = rescaled_image.flatten()\n",
        "\n",
        "dum = rescaled_image.reshape(1, -1)/255\n",
        "dum.shape\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  saver.restore(sess, \"./model/my_model.ckpt\")\n",
        "  Z = output_layer.eval(feed_dict = {X: dum, keep_prob: 1.0})\n",
        "  y_pred = np.argmax(Z, axis = 1)\n",
        "  print(\"Prediction for test image is {0}\".format(y_pred)) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Prediction for test image is [9]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}